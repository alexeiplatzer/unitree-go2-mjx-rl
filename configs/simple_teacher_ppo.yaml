model:
  hidden_sizes: [128, 128, 128, 128]

training:
  num_learning_iterations: 4000
  eval_freq: 100
  
  # runner
  algorithm_class_name: PPO
  num_steps_per_env: 24  # per iteration
  max_iterations: 1500  # number of policy updates

  # logging
  save_interval: 400  # check for potential saves every this many iterations
  save_video_interval: 100
  log_freq: 10

  # load and resume
  resume: false
  load_run: -1  # -1: last run
  checkpoint: -1  # -1: last saved model
  resume_path: None  # updated from load_run and chkpt
  
  # algorithm
  value_loss_coef: 1.0
  use_clipped_value_loss: True
  clip_param: 0.2
  entropy_coef: 0.01
  num_learning_epochs: 5
  num_mini_batches: 4  # mini batch size = num_envs*nsteps / nminibatches
  learning_rate: 1.0e-3  # 5.e-4
  adaptation_module_learning_rate: 1.0e-3
  num_adaptation_module_substeps: 1
  schedule: "adaptive"  # could be adaptive, fixed
  gamma: 0.99
  lam: 0.95
  desired_kl: 0.01
  max_grad_norm: 1.0
  
  # policy
  init_noise_std: 1.0
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [512, 256, 128]
  activation: "elu"  # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid

  adaptation_module_branch_hidden_dims: [[256, 32]]

  env_factor_encoder_branch_input_dims: [18]
  env_factor_encoder_branch_latent_dims: [18]
  env_factor_encoder_branch_hidden_dims: [[256, 128]]
  
environment:
  init_state:
    initial_keyframe: home
#    pos: [0.0, 0.0, 0.34]  # x,y,z [m]
#    rot: [0.0, 0.0, 0.0, 1.0]  # x,y,z,w [quat]
#    lin_vel: [0.0, 0.0, 0.0]  # x,y,z [m/s]
#    ang_vel: [0.0, 0.0, 0.0]  # x,y,z [rad/s]
#    default_joint_angles:  # = target angles [rad] when action = 0.0
#      FL_hip_joint: 0.1,  # [rad]
#      RL_hip_joint: 0.1,  # [rad]
#      FR_hip_joint: -0.1,  # [rad]
#      RR_hip_joint: -0.1,  # [rad]
#      FL_thigh_joint: 0.8,  # [rad]
#      RL_thigh_joint: 1.0,  # [rad]
#      FR_thigh_joint: 0.8,  # [rad]
#      RR_thigh_joint: 1.0,  # [rad]
#      FL_calf_joint: -1.5,  # [rad]
#      RL_calf_joint: -1.5,  # [rad]
#      FR_calf_joint: -1.5,  # [rad]
#      RR_calf_joint: -1.5,  # [rad]

  control:
    control_type: P
    stiffness:
      joint: 20.0  # [N*m/rad]
    damping:
      joint: 0.5  # [N*m*s/rad]
    # action scale: target angle = actionScale * action + defaultAngle
    action_scale: 0.25
    hip_scale_reduction: 0.5
    # decimation: Number of control action updates @ sim DT per policy DT
    decimation: 4

  asset:
    file: "{MINIYMOOTIR}/resources/robots/go1/urdf/go1.urdf"
    foot_name: foot
    penalize_contacts_on: [thigh, calf]
    terminate_after_contacts_on: [base]
    disable_gravity: false
    # merge bodies connected by fixed joints. 
    # Specific fixed joints can be kept by adding " <... dont_collapse="true">
    collapse_fixed_joints: false
    # see GymDofDriveModeFlags (0 is none, 1 is pos tgt, 2 is vel tgt, 3 effort)
    default_dof_drive_mode: 3  
    self_collisions: 0  # 1 to disable, 0 to enable...bitwise filter
    # replace collision cylinders with capsules, leads to faster/more stable simulation
    replace_cylinder_with_capsule: true
    flip_visual_attachments: false
    fix_base_link: false  # fix the base of the robot
    
    density: 0.001
    angular_damping: 0.0
    linear_damping: 0.0
    max_angular_velocity: 1000.0
    max_linear_velocity: 1000.0
    armature: 0.0
    thickness: 0.01

  rewards:
    only_positive_rewards: True  # if true negative total rewards are clipped at zero (avoids early termination problems)
    tracking_sigma: 0.25  # tracking reward = exp(-error^2/sigma)
    tracking_sigma_lat: 0.25  # tracking reward = exp(-error^2/sigma)
    tracking_sigma_long: 0.25  # tracking reward = exp(-error^2/sigma)
    tracking_sigma_yaw: 0.25  # tracking reward = exp(-error^2/sigma)
    soft_dof_pos_limit: 0.9
    soft_dof_vel_limit: 1.0
    soft_torque_limit: 1.0
    base_height_target: 0.34
    max_contact_force: 100.0  # forces above this value are penalized
    termination_body_height: 0.20
    
    scales:
      termination: -0.0
      tracking_lin_vel: 1.0
      tracking_ang_vel: 0.5
      lin_vel_z: -2.0
      ang_vel_xy: -0.05
      orientation: -5.0
      torques: -0.0001
      dof_vel: -0.0
      dof_acc: -2.5e-7
      base_height: -30.0
      feet_air_time: 1.0
      collision: -1.0
      feet_stumble: -0.0
      action_rate: -0.01
      stand_still: -0.0
      tracking_lin_vel_lat: 0.0
      tracking_lin_vel_long: 0.0
      dof_pos_limits: -10.0

  terrain:
    mesh_type: "trimesh"  # "heightfield" # none, plane, heightfield or trimesh
    horizontal_scale: 0.1  # [m]
    vertical_scale: 0.005  # [m]
    border_size: 50  # 25 # [m]
    curriculum: false
    static_friction: 1.0
    dynamic_friction: 1.0
    restitution: 0.0
    terrain_noise_magnitude: 0.0
    # rough terrain only:
    terrain_smoothness: 0.005
    measure_heights: false
    # 1mx1.6m rectangle (without center line)
    measured_points_x: [-0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    measured_points_y: [-0.5, -0.4, -0.3, -0.2, -0.1, 0.0, 0.1, 0.2, 0.3, 0.4, 0.5]
    selected: false  # select a unique terrain type and pass all arguments
    terrain_kwargs: None  # Dict of arguments for selected terrain
    min_init_terrain_level: 0
    max_init_terrain_level: 5  # starting curriculum state
    terrain_length: 8.0
    terrain_width: 8.0
    num_rows: 10  # number of terrain rows (levels)
    num_cols: 20  # number of terrain cols (types)
    # terrain types: [smooth slope, rough slope, stairs up, stairs down, discrete]
    terrain_proportions: [0, 0, 0, 0, 0, 0, 0, 0, 1.0]
    # trimesh only:
    # slopes above this threshold will be corrected to vertical surfaces
    slope_threshold: 0.75
    difficulty_scale: 1.0
    x_init_range: 1.0
    y_init_range: 1.0
    x_init_offset: 0.0
    y_init_offset: 0.0
    teleport_robots: true
    teleport_thresh: 2.0
    max_platform_height: 0.2
    
  env:
    num_envs: 4000
    num_observations: 42
    num_privileged_obs: 18
    privileged_future_horizon: 1
    num_actions: 12
    num_observation_history: 15
    env_spacing: 3.0  # not used with heightfields/trimeshes
    send_timeouts: true  # send time out information to the algorithm
    episode_length_s: 20  # episode length in seconds
    observe_vel: false
    observe_only_ang_vel: false
    observe_only_lin_vel: false
    observe_yaw: false
    observe_command: true
    record_video: true
    
    priv_observe_friction: true
    priv_observe_restitution: true
    priv_observe_base_mass: true
    priv_observe_com_displacement: true
    priv_observe_motor_strength: true
    priv_observe_Kp_factor: true
    priv_observe_Kd_factor: true


  commands:
    command_curriculum: true
    max_reverse_curriculum: 1.0
    max_forward_curriculum: 1.0
    forward_curriculum_threshold: 0.8
    yaw_command_curriculum: false
    max_yaw_curriculum: 1.0
    yaw_curriculum_threshold: 0.5
    num_commands: 4
    resampling_time: 500.0  # time before command are changed[s]
    heading_command: false  # if true: compute ang vel command from heading error
    global_reference: false
    
    num_lin_vel_bins: 30
    lin_vel_step: 0.3
    num_ang_vel_bins: 30
    ang_vel_step: 0.3
    distribution_update_extension_distance: 1
    curriculum_seed: 100
    
    # class ranges(ParamsProto, cli=false, prefix="commands.ranges"):
    lin_vel_x: [-0.6, 0.6]  # min max [m/s]
    lin_vel_y: [-0.6, 0.6]  # min max [m/s]
    ang_vel_yaw: [-1, 1]  # min max [rad/s]
    body_height_cmd: [-0.05, 0.05]
    impulse_height_commands: false
    
    limit_vel_x: [-10.0, 10.0]
    limit_vel_y: [-0.6, 0.6]
    limit_vel_yaw: [-10.0, 10.0]

    heading: [-3.14, 3.14]

  domain_rand:
    randomize_base_mass: true
    added_mass_range: [-1.0, 3.0]
    kick_interval: 10
    kick_vel: 0.05
    randomize_friction: true
    friction_range: [0.05, 4.5]
    randomize_restitution: true
    restitution_range: [0.0, 1.0]
    restitution: 0.5  # default terrain restitution
    randomize_com_displacement: true
    com_displacement_range: [-0.1, 0.1]
    randomize_motor_strength: true
    motor_strength_range: [0.9, 1.1]
    randomize_Kp_factor: false
    Kp_factor_range: [0.8, 1.3]
    randomize_Kd_factor: false
    Kd_factor_range: [0.5, 1.5]
    rand_interval_s: 6
    
  normalization:
    clip_observations: 100.0
    clip_actions: 100.0

    friction_range: [0.05, 4.5]  # increase range
    restitution_range: [0, 1.0]
    added_mass_range: [-1.0, 3.0]
    com_displacement_range: [-0.1, 0.1]
    motor_strength_range: [0.9, 1.1]
    Kp_factor_range: [0.8, 1.3]
    Kd_factor_range: [0.5, 1.5]
  
    obs_scales:
      lin_vel: 2.0
      ang_vel: 0.25
      dof_pos: 1.0
      dof_vel: 0.05
      height_measurements: 5.0
      body_height_cmd: 2.0
    
  noise:
    add_noise: true
    noise_level: 1.0  # scales other values
    
    noise_scales:
      dof_pos: 0.01
      dof_vel: 1.5
      lin_vel: 0.1
      ang_vel: 0.2
      gravity: 0.05
      height_measurements: 0.1
    
  sim:
    dt: 0.02
    timestep: 0.004
    gravity: [0.0, 0.0, -9.81]  # [m/s^2]
    up_axis: 1  # 0 is y, 1 is z