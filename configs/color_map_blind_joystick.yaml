environment:
  command:
    ranges:
      ang_vel_yaw_max: 0.7
      ang_vel_yaw_min: -0.7
      lin_vel_x_max: 1.5
      lin_vel_x_min: -0.6
      lin_vel_y_max: 0.8
      lin_vel_y_min: -0.8
    resampling_time: 500
  control:
    action_scale: 0.3
  domain_rand:
    apply_kicks: false
    kick_interval: 10
    kick_vel: 0.05
  environment_class: JoystickBase
  observation_noise:
    add_privileged_obs: false
    clip: 100.0
    extended_history_length: null
    general_noise: 0.05
    history_length: 15
  rewards:
    reward_clip_max: 10000.0
    reward_clip_min: -100.0
    scales:
      action_rate: -0.01
      ang_vel_xy: -0.05
      feet_air_time: 0.2
      foot_slip: -0.1
      lin_vel_z: -2.0
      orientation: -5.0
      stand_still: -0.5
      termination: -1.0
      torques: -0.0002
      tracking_ang_vel: 0.8
      tracking_lin_vel: 1.5
    termination_body_height: 0.18
    tracking_sigma: 0.25
  sim:
    ctrl_dt: 0.02
    override:
      Kd: 0.5
      Kp: 35.0
    sim_dt: 0.004
model:
  model_class: ActorCritic
  policy:
    layer_sizes:
    - 128
    - 128
    - 128
    - 128
    obs_key: proprioceptive
  value:
    layer_sizes:
    - 256
    - 256
    - 256
    - 256
    obs_key: proprioceptive
terrain:
  add_goal: false
  base_scene_file: scene_mjx_vision.xml
  column_offset: 5
  egocentric_camera:
    fovy: 80
    location:
    - 0.3
    - 0.0
    - 0.1
    mode: fixed
    name: frontal_ego
    orthographic: false
    xyaxes:
    - 0
    - -1
    - 0
    - 0
    - 0
    - 1
  floor_thickness: 0.05
  goal_location:
  - 20
  - 0
  - 2
  goal_size: 2
  n_columns: 20
  n_rows: 5
  randomization_config:
    num_colors: 2
    tile_body_prefix: tile_
  square_size: 1.0
  terrain_class: ColorMap
  terrain_map_camera:
    fovy: 5
    location:
    - 2
    - 0
    - 2
    mode: track
    name: terrain_map
    orthographic: true
    xyaxes:
    - 0
    - -1
    - 0
    - 1
    - 0
    - 0
training:
  action_repeat: 1
  augment_pixels: false
  batch_size: 64
  deterministic_eval: false
  episode_length: 4096
  log_training_metrics: false
  normalize_observations: true
  num_envs: 2048
  num_eval_envs: 2048
  num_evals: 9
  num_minibatches: 32
  num_resets_per_eval: 0
  num_timesteps: 134217728
  num_updates_per_batch: 4
  optimizer:
    learning_rate: 0.0002
    max_grad_norm: null
  rl_hyperparams:
    clipping_epsilon: 0.3
    discounting: 0.97
    entropy_cost: 0.01
    gae_lambda: 0.95
    normalize_advantage: true
    reward_scaling: 1
  seed: 0
  training_class: default
  training_metrics_steps: null
  unroll_length: 64
  vision_config: null
