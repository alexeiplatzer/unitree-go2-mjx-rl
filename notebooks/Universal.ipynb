{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexeiplatzer/unitree-go2-mjx-rl/blob/main/notebooks/Universal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "255c3b44bb8069ff"
  },
  {
   "metadata": {
    "id": "c25e3c5b2c398381"
   },
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/alexeiplatzer/unitree-go2-mjx-rl/blob/main/notebooks/Universal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "id": "c25e3c5b2c398381"
  },
  {
   "metadata": {
    "id": "9bec00bce4d746bb"
   },
   "cell_type": "markdown",
   "source": [
    "# **Univeral Notebook for Quadruped RL Training in MJX**\n",
    "This notebook uses the `quadruped-mjx-rl` python package from the `unitree-go2-mjx-rl` repository to train locomotion policies for quadrupeds using reinforcement learning in the Mujoco XLA (MJX) simulation environment."
   ],
   "id": "9bec00bce4d746bb"
  },
  {
   "metadata": {
    "id": "4570be9069e70fa6"
   },
   "cell_type": "markdown",
   "source": [
    "# Hardware Setup\n",
    "This part sets up the `quadruped-mjx-rl` package on the machine."
   ],
   "id": "4570be9069e70fa6"
  },
  {
   "metadata": {
    "id": "520e69f754d50a8c"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title run this cell once each time on a new machine\n",
    "#@markdown #### Setup configuration\n",
    "\n",
    "#@markdown Choose your hardware option:\n",
    "hardware = \"Colab\" #@param [\"local\",\"Colab\",\"Kaggle\"]\n",
    "\n",
    "#@markdown Choose whether you want to build the madrona rendering setup for training\n",
    "#@markdown with vision:\n",
    "build_madrona_backend = False #@param {\"type\":\"boolean\"}\n",
    "\n",
    "#@markdown Choose if you want to pull changes to the package repository during the runtime.\n",
    "#@markdown (Requires a restart after executing this cell!)\n",
    "editable_mode = True #@param {\"type\":\"boolean\"}\n",
    "\n",
    "if build_madrona_backend:\n",
    "    # Install madrona MJX\n",
    "    import time\n",
    "    print(\"Intalling Madrona MJX...\")\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    print(\"Setting up environment... (Step 1/3)\")\n",
    "\n",
    "    if hardware==\"Kaggle\":\n",
    "        # Install the 12.4 cuda toolkit\n",
    "        !wget -qO cuda-keyring.deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb\n",
    "        !sudo dpkg -i ./cuda-keyring.deb\n",
    "        !sudo apt-get update -y -qq\n",
    "        !sudo apt-get install -y -qq cuda-toolkit-12-4\n",
    "        %CUDA_HOME=/usr/local/cuda-12.4\n",
    "        %CUDAToolkit_ROOT=/usr/local/cuda-12.4\n",
    "        %XLA_FLAGS=\"--xla_gpu_cuda_data_dir=/usr/local/cuda-12.4\"\n",
    "        %PATH=\"/usr/local/cuda-12.4/bin:$PATH\"\n",
    "        %LD_LIBRARY_PATH=\"/usr/local/cuda-12.4/lib64:${LD_LIBRARY_PATH}\"\n",
    "\n",
    "    !pip install jax[\"cuda12\"]==0.5.1\n",
    "\n",
    "    !sudo apt install libx11-dev libxrandr-dev libxinerama-dev libxcursor-dev libxi-dev mesa-common-dev\n",
    "\n",
    "    !mkdir modules\n",
    "    !git clone https://github.com/shacklettbp/madrona_mjx.git modules/madrona_mjx\n",
    "    !git -C modules/madrona_mjx submodule update --init --recursive\n",
    "    !mkdir modules/madrona_mjx/build\n",
    "\n",
    "    print(\"Building the Madrona backend ... (Step 2/3)\")\n",
    "    !cmake -S modules/madrona_mjx -B modules/madrona_mjx/build -DLOAD_VULKAN=OFF\n",
    "    !cmake --build modules/madrona_mjx/build -j\n",
    "\n",
    "    print (\"Installing Madrona MJX ... (Step 3/3)\")\n",
    "    !pip install modules/madrona_mjx\n",
    "\n",
    "    minutes, seconds = divmod((time.perf_counter() - start_time), 60)\n",
    "    print(f\"Finished installing Madrona MJX in {minutes} m {seconds:.2f} s\")\n",
    "\n",
    "# Clones and installs our Quadruped RL package\n",
    "!git clone https://github.com/alexeiplatzer/unitree-go2-mjx-rl.git\n",
    "if editable_mode:\n",
    "    !pip install -e unitree-go2-mjx-rl\n",
    "else:\n",
    "    !pip install unitree-go2-mjx-rl"
   ],
   "id": "520e69f754d50a8c"
  },
  {
   "metadata": {
    "id": "8ba04058f98f5a97"
   },
   "cell_type": "markdown",
   "source": [
    "### Now restart the session and continue.\n",
    "### You can skip setup next time while you are on the same machine."
   ],
   "id": "8ba04058f98f5a97"
  },
  {
   "metadata": {
    "id": "a04ad83b7ff6e72d"
   },
   "cell_type": "markdown",
   "source": [
    "# Refresh package after pushed to the repo. Important in development"
   ],
   "id": "a04ad83b7ff6e72d"
  },
  {
   "metadata": {
    "id": "45a111e735248029"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "repo_path = \"./unitree-go2-mjx-rl\"\n",
    "!git -C {repo_path} pull"
   ],
   "id": "45a111e735248029"
  },
  {
   "metadata": {
    "id": "8a5be0b84cebcccc"
   },
   "cell_type": "markdown",
   "source": [
    "# Setup session and configs\n",
    "Run once in the beggining of every session, i.e. after restarts and crashes."
   ],
   "id": "8a5be0b84cebcccc"
  },
  {
   "metadata": {
    "cellView": "code",
    "id": "f1d2b3c9cd0f3740"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title Expand\n",
    "\n",
    "# Configure logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "logging.info(\"Logging switched on.\")\n",
    "\n",
    "#@markdown Choose whether you want to use the madrona backend for parallelized vision rendering\n",
    "use_madrona_backend = False #@param {\"type\":\"boolean\"}\n",
    "\n",
    "if use_madrona_backend:\n",
    "    from pathlib import Path\n",
    "    # On your second reading, load the compiled rendering backend to save time!\n",
    "    cache_path = Path(\"modules/madrona_mjx/build/cache\")\n",
    "    if cache_path.exists():\n",
    "        os.environ[\"MADRONA_MWGPU_KERNEL_CACHE\"] = \"modules/madrona_mjx/build/cache\"\n",
    "        logging.info(\"Madrona cache located and will be used.\")\n",
    "    # Ensure that Madrona gets the chance to pre-allocate memory before Jax\n",
    "    os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "\n",
    "# Check if there is a GPU on the machine\n",
    "import subprocess\n",
    "if subprocess.run('nvidia-smi').returncode:\n",
    "    raise RuntimeError(\n",
    "        'Cannot communicate with GPU. '\n",
    "        'Make sure you are using a GPU Colab runtime. '\n",
    "        'Go to the Runtime menu and select Choose runtime type.'\n",
    "    )\n",
    "\n",
    "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
    "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
    "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
    "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
    "import os\n",
    "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "    with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "        f.write(\"\"\"{\n",
    "        \"file_format_version\" : \"1.0.0\",\n",
    "        \"ICD\" : {\n",
    "            \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "        }\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "logging.info('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n",
    "\n",
    "try:\n",
    "    logging.info('Checking that the installation succeeded:')\n",
    "    import mujoco\n",
    "\n",
    "    mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "        'Something went wrong during installation. Check the shell output above '\n",
    "        'for more information.\\n'\n",
    "        'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "        'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
    "    )\n",
    "\n",
    "logging.info('Mujoco installation successful.')\n",
    "\n",
    "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
    "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "os.environ['XLA_FLAGS'] = xla_flags\n",
    "\n",
    "# More legible printing from numpy.\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "\n",
    "# Prepare directories\n",
    "from etils.epath import Path\n",
    "repo_path = Path(\"unitree-go2-mjx-rl\")\n",
    "experiments_dir = Path(\"experiments\")\n",
    "trained_policy_dir = experiments_dir / \"trained_policies\"\n",
    "!mkdir -p {trained_policy_dir}\n",
    "configs_dir = experiments_dir / \"configs\"\n",
    "!mkdir -p {configs_dir}\n",
    "rollout_configs_dir = configs_dir / \"rollout_configs\"\n",
    "!mkdir -p {rollout_configs_dir}\n",
    "animations_dir = experiments_dir / \"rendered_rollouts\"\n",
    "!mkdir -p {animations_dir}\n",
    "\n",
    "#@markdown ---\n",
    "from quadruped_mjx_rl.robots import predefined_robot_configs\n",
    "#@markdown #### Choose the robot\n",
    "robot = \"unitree_go2\" #@param [\"unitree_go2\", \"google_barkour_vb\"]\n",
    "robot_config = predefined_robot_configs[robot]()\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Choose the model architecture and set its hyperparameters\n",
    "from quadruped_mjx_rl import models\n",
    "model_architecture = \"ActorCritic\" #@param [\"ActorCritic\",\"TeacherStudent\",\"TeacherStudentVision\"]\n",
    "#@markdown ---\n",
    "#@markdown **Model hyperparameters for the Actor-Critic Architecture**\n",
    "if model_architecture == \"ActorCritic\":\n",
    "    policy_dense_layers = [128, 128, 128, 128, 128] #@param\n",
    "    value_dense_layers = [256, 256, 256, 256, 256] #@param\n",
    "    model_config = models.ActorCriticConfig(\n",
    "        policy=models.ModuleConfigMLP(layer_sizes=policy_dense_layers),\n",
    "        value=models.ModuleConfigMLP(layer_sizes=value_dense_layers),\n",
    "    )\n",
    "#@markdown ---\n",
    "#@markdown **Model hyperparameters for the Teacher-Student Architecture**\n",
    "if model_architecture == \"TeacherStudent\":\n",
    "    policy_dense_layers = [256, 256, 256] #@param\n",
    "    value_dense_layers = [256, 256, 256] #@param\n",
    "    teacher_dense_layers = [256, 256] #@param\n",
    "    student_dense_layers = [256, 256] #@param\n",
    "    latent_representation_size = 64 #@param {\"type\":\"integer\"}\n",
    "\n",
    "    model_config = models.TeacherStudentConfig(\n",
    "        policy=models.ModuleConfigMLP(layer_sizes=policy_layers),\n",
    "        value=models.ModuleConfigMLP(layer_sizes=value_layers),\n",
    "        encoder=models.ModuleConfigMLP(layer_sizes=teacher_dense_layers),\n",
    "        student=models.ModuleConfigMLP(layer_sizes=student_dense_layers),\n",
    "        latent_encoding_size=latent_representation_size,\n",
    "    )\n",
    "#@markdown ---\n",
    "#@markdown **Model hyperparameters for the Teacher-Student-Vision Architecture**\n",
    "if model_architecture == \"TeacherStudentVision\":\n",
    "    policy_dense_layers = [128, 128] #@param\n",
    "    value_dense_layers = [256, 256] #@param\n",
    "    teacher_convolutional_layers = [32, 64, 64] #@param\n",
    "    teacher_dense_layers = [256, 256] #@param\n",
    "    student_convolutional_layers = [32, 64, 64] #@param\n",
    "    student_dense_layers = [256, 256] #@param\n",
    "    latent_representation_size = 128 #@param {\"type\":\"integer\"}\n",
    "    proprioceptive_observations_per_vision_observation = 16 #@param {\"type\":\"integer\"}\n",
    "\n",
    "    model_config_class = models.TeacherStudentVisionConfig\n",
    "    model_config = model_config_class(\n",
    "        policy=models.ModuleConfigMLP(layer_sizes=policy_layers),\n",
    "        value=models.ModuleConfigMLP(layer_sizes=value_layers),\n",
    "        encoder=models.ModuleConfigCNN(\n",
    "            filter_sizes=teacher_convolutional_layers,\n",
    "            dense=models.ModuleConfigMLP(layer_sizes=teacher_dense_layers),\n",
    "        ),\n",
    "        student=models.ModuleConfigCNN(\n",
    "            filter_sizes=student_convolutional_layers,\n",
    "            dense=models.ModuleConfigMLP(layer_sizes=student_dense_layers),\n",
    "        ),\n",
    "        latent_encoding_size=latent_representation_size,\n",
    "        encoder_supersteps=proprioceptive_observations_per_vision_observation,\n",
    "    )\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Configure the Environment\n",
    "from quadruped_mjx_rl import environments\n",
    "\n",
    "model_architecture = type(model_config).config_class_key()\n",
    "if model_architecture == \"TeacherStudentVision\":\n",
    "    env_config_class = environments.QuadrupedJoystickVisionEnvConfig\n",
    "elif model_architecture == \"TeacherStudent\":\n",
    "    env_config_class = environments.TeacherStudentEnvironmentConfig\n",
    "elif model_architecture == \"ActorCritic\":\n",
    "    env_config_class = environments.JoystickBaseEnvConfig\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO: add support for more environment params\n",
    "simulation_timestep = 0.002 #@param {type:\"number\"}\n",
    "control_timestep = 0.04 #@param {type:\"number\"}\n",
    "\n",
    "environment_config = env_config_class(\n",
    "    sim=env_config_class.SimConfig(\n",
    "        sim_dt=simulation_timestep,\n",
    "        ctrl_dt=control_timestep,\n",
    "    ),\n",
    ")\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Configure the training process\n",
    "from quadruped_mjx_rl.training.configs import (\n",
    "    TrainingConfig,\n",
    "    TrainingWithVisionConfig,\n",
    "    OptimizerConfig,\n",
    "    TeacherStudentOptimizerConfig,\n",
    ")\n",
    "from quadruped_mjx_rl.training.algorithms.ppo import HyperparamsPPO\n",
    "from quadruped_mjx_rl.environments.vision.robotic_vision import RendererConfig\n",
    "model_architecture = type(model_config).config_class_key()\n",
    "#@markdown ---\n",
    "#@markdown **PPO Hyperparameters**\n",
    "discounting = 0.97 #@param {\"type\":\"number\"}\n",
    "entropy_cost = 0.01 #@param {\"type\":\"number\"}\n",
    "clipping_epsilon = 0.3 #@param {\"type\":\"number\"}\n",
    "gae_lambda = 0.95 #@param {\"type\":\"number\"}\n",
    "normalize_advantage = True #@param {\"type\":\"boolean\"}\n",
    "reward_scaling = 1 #@param {\"type\":\"integer\"}\n",
    "learning_rate = 0.0004 #@param {\"type\":\"number\"}\n",
    "ppo_hyperparams = HyperparamsPPO(\n",
    "    discounting=discounting,\n",
    "    entropy_cost=entropy_cost,\n",
    "    clipping_epsilon=clipping_epsilon,\n",
    "    gae_lambda=gae_lambda,\n",
    "    normalize_advantage=normalize_advantage,\n",
    ")\n",
    "#@markdown **Teacher-Student specific hyperparameters**\n",
    "#@markdown ---\n",
    "if model_architecture == \"TeacherStudent\" or model_architecture == \"TeacherStudentVision\":\n",
    "    student_learning_rate = 0.001 #@param {\"type\":\"number\"}\n",
    "    max_grad_norm = 1.0 #@param\n",
    "    optimizer_config = TeacherStudentOptimizerConfig(\n",
    "        learning_rate=learning_rate,\n",
    "        student_learning_rate=student_learning_rate,\n",
    "        max_grad_norm=max_grad_norm,\n",
    "    )\n",
    "else:\n",
    "    optimizer_config = OptimizerConfig(learning_rate=learning_rate)\n",
    "#@markdown ---\n",
    "#@markdown **Training hyperparameters without vision**\n",
    "if model_architecture == \"ActorCritic\" or model_architecture == \"TeacherStudent\":\n",
    "    num_envs = 8192 #@param {\"type\":\"integer\"}\n",
    "    num_eval_envs = 8192 #@param {\"type\":\"integer\"}\n",
    "    seed = 0 #@param {\"type\":\"integer\"}\n",
    "    num_timesteps = 100_000_000 #@param {\"type\":\"integer\"}\n",
    "    num_evals = 10 #@param {\"type\":\"integer\"}\n",
    "    deterministic_eval = False #@param {\"type\":\"boolean\"}\n",
    "    num_resets_per_eval = 0 #@param {\"type\":\"integer\"}\n",
    "    episode_length = 1000 #@param {\"type\":\"integer\"}\n",
    "    unroll_length = 20 #@param {\"type\":\"integer\"}\n",
    "    normalize_observations = True  #@param {\"type\":\"boolean\"}\n",
    "    action_repeat = 1 #@param {\"type\":\"integer\"}\n",
    "    batch_size = 256 #@param {\"type\":\"integer\"}\n",
    "    num_updates_per_batch = 4 #@param {\"type\":\"integer\"}\n",
    "    num_minibatches = 32 #@param {\"type\":\"integer\"}\n",
    "    training_config = TrainingConfig(\n",
    "        num_envs=num_envs,\n",
    "        num_eval_envs=num_eval_envs,\n",
    "        seed=seed,\n",
    "        num_timesteps=num_timesteps,\n",
    "        num_evals=num_evals,\n",
    "        deterministic_eval=deterministic_eval,\n",
    "        num_resets_per_eval=num_resets_per_eval,\n",
    "        episode_length=episode_length,\n",
    "        unroll_length=unroll_length,\n",
    "        normalize_observations=normalize_observations,\n",
    "        action_repeat=action_repeat,\n",
    "        batch_size=batch_size,\n",
    "        num_updates_per_batch=num_updates_per_batch,\n",
    "        num_minibatches=num_minibatches,\n",
    "        rl_hyperparams=ppo_hyperparams,\n",
    "        optimizer=optimizer_config\n",
    "    )\n",
    "    vision_config = None\n",
    "#@markdown ---\n",
    "#@markdown **Training hyperparameters with vision**\n",
    "elif model_architecture == \"TeacherStudentVision\":\n",
    "    num_envs = 256 #@param {\"type\":\"integer\"}\n",
    "    num_eval_envs = 256 #@param {\"type\":\"integer\"}\n",
    "    seed = 0 #@param {\"type\":\"integer\"}\n",
    "    num_timesteps = 100_000_000 #@param {\"type\":\"integer\"}\n",
    "    num_evals = 10 #@param {\"type\":\"integer\"}\n",
    "    deterministic_eval = False #@param {\"type\":\"boolean\"}\n",
    "    num_resets_per_eval = 0 #@param {\"type\":\"integer\"}\n",
    "    episode_length = 1000 #@param {\"type\":\"integer\"}\n",
    "    unroll_length = 20 #@param {\"type\":\"integer\"}\n",
    "    normalize_observations = True  #@param {\"type\":\"boolean\"}\n",
    "    action_repeat = 1\n",
    "    batch_size = 256 #@param {\"type\":\"integer\"}\n",
    "    num_updates_per_batch = 4 #@param {\"type\":\"integer\"}\n",
    "    num_minibatches = 32 #@param {\"type\":\"integer\"}\n",
    "    training_config = TrainingWithVisionConfig(\n",
    "        num_envs=num_envs,\n",
    "        num_eval_envs=num_eval_envs,\n",
    "        seed=seed,\n",
    "        num_timesteps=num_timesteps,\n",
    "        num_evals=num_evals,\n",
    "        deterministic_eval=deterministic_eval,\n",
    "        num_resets_per_eval=num_resets_per_eval,\n",
    "        episode_length=episode_length,\n",
    "        unroll_length=unroll_length,\n",
    "        normalize_observations=normalize_observations,\n",
    "        action_repeat=action_repeat,\n",
    "        batch_size=batch_size,\n",
    "        num_updates_per_batch=num_updates_per_batch,\n",
    "        num_minibatches=num_minibatches,\n",
    "        rl_hyperparams=ppo_hyperparams,\n",
    "        optimizer=optimizer_config,\n",
    "    )\n",
    "#@markdown **Vision renderer parameters**\n",
    "    enabled_cameras=[0, 1, 2] # @param\n",
    "    enabled_geom_groups=[0, 1, 2] # @param\n",
    "    render_width=64 # @param {\"type\": \"integer\"}\n",
    "    render_height=64 # @param {\"type\": \"integer\"}\n",
    "    vision_config = RendererConfig(\n",
    "        render_batch_size=training_config.num_envs,\n",
    "        enabled_cameras=enabled_cameras,\n",
    "        enabled_geom_groups=enabled_geom_groups,\n",
    "        render_width=render_width,\n",
    "        render_height=render_height,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Configure the terrain generation\n",
    "use_challenging_terrain = True #@param {\"type\":\"boolean\"}\n",
    "if use_challenging_terrain:\n",
    "    from quadruped_mjx_rl.terrain_gen.obstacles import FlatTile, StripesTile\n",
    "    from quadruped_mjx_rl.terrain_gen.configs import TiledTerrainConfig\n",
    "    flat_tile = FlatTile()\n",
    "    stripes_tile = StripesTile()\n",
    "    terrain_config = TiledTerrainConfig(tiles=[[\n",
    "        FlatTile(),\n",
    "        StripesTile(stripe_amplitude=0.04),\n",
    "        StripesTile(stripe_amplitude=0.08),\n",
    "        StripesTile(stripe_amplitude=0.12),\n",
    "        StripesTile(stripe_amplitude=0.16),\n",
    "    ]])\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown #### Save configs\n",
    "from quadruped_mjx_rl.config_utils import save_configs\n",
    "#@markdown Fill out a name for the experiment and all configuration parameters.\n",
    "#@markdown If you want to add another experiment, change the parameters and run\n",
    "#@markdown this cell again.\n",
    "experiment_name = \"my_experiment\" # @param {type:\"string\"}\n",
    "config_file_path = configs_dir / f\"{experiment_name}.yaml\"\n",
    "configs_to_save = [robot_config, model_config, environment_config, training_config]\n",
    "if vision_config is not None:\n",
    "    configs_to_save.append(vision_config)\n",
    "# if use_challenging_terrain:\n",
    "#     configs_to_save.append(terrain_config)\n",
    "save_configs(config_file_path, *configs_to_save)\n",
    "print(f\"Experiment configs saved to {config_file_path}\")\n"
   ],
   "id": "f1d2b3c9cd0f3740"
  },
  {
   "metadata": {
    "id": "271ede6e4c338bef"
   },
   "cell_type": "markdown",
   "source": [
    "# Run training, visualisation, and save results\n",
    "This visualisation can be run independently from the training section, including after restarts and crashes. As long as all the created files remain in the session's disk memory."
   ],
   "id": "271ede6e4c338bef"
  },
  {
   "metadata": {
    "id": "3707f41b1d929687"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Expand\n",
    "\n",
    "logging.info(\"Listing all the configuration files:\")\n",
    "!ls {configs_dir}\n",
    "\n",
    "#@markdown ---\n",
    "import functools\n",
    "from quadruped_mjx_rl.config_utils import prepare_configs\n",
    "from quadruped_mjx_rl.training.train_interface import train\n",
    "from quadruped_mjx_rl import environments\n",
    "from quadruped_mjx_rl.environments import get_env_factory\n",
    "from quadruped_mjx_rl.physics_pipeline import load_to_spec, spec_to_model\n",
    "from quadruped_mjx_rl.environments.rendering import render_model, large_overview_camera\n",
    "\n",
    "#@markdown Choose with which configs to train\n",
    "#@markdown All chosen experiments will be run sequentially\n",
    "training_runs = None # @param {\"type\":\"raw\",\"placeholder\":\"[\\\"experiment_name1\\\", \\\"experiment_name2\\\", ... ]\"}\n",
    "# @markdown or\n",
    "run_them_all = True # @param {\"type\":\"boolean\"}\n",
    "if run_them_all:\n",
    "    training_runs = [\n",
    "        config_file.stem\n",
    "        for config_file in configs_dir.iterdir() if config_file.name.endswith(\".yaml\")\n",
    "    ]\n",
    "\n",
    "\n",
    "for experiment_name in training_runs:\n",
    "    config_path = configs_dir / f\"{experiment_name}.yaml\"\n",
    "    configs = prepare_configs(config_path)\n",
    "    environment_config = configs[\"environment\"]\n",
    "    robot_config = configs[\"robot\"]\n",
    "    model_config = configs[\"model\"]\n",
    "    training_config = configs[\"training\"]\n",
    "    vision_config = configs.get(\"vision\")\n",
    "    # terrain_config = configs.get(\"terrain\")\n",
    "\n",
    "    if terrain_config is not None:\n",
    "        scene_file = \"scene_mjx_empty_arena.xml\"\n",
    "    elif isinstance(environment_config, environments.QuadrupedJoystickVisionEnvConfig):\n",
    "        scene_file = \"scene_mjx_vision.xml\"\n",
    "    else:\n",
    "        scene_file = \"scene_mjx.xml\"\n",
    "    init_scene_path = repo_path / \"resources\" / robot_config.robot_name / scene_file\n",
    "\n",
    "    env_spec = load_to_spec(init_scene_path)\n",
    "    if terrain_config is not None:\n",
    "        terrain_config.make_arena(env_spec)\n",
    "    env_model = spec_to_model(env_spec)\n",
    "    env_model = environments.QuadrupedJoystickBaseEnv.customize_model(\n",
    "        env_model, environment_config\n",
    "    )\n",
    "\n",
    "    render_model(env_model=env_model, camera=large_overview_camera())\n",
    "\n",
    "    if vision_config is not None:\n",
    "        # instantiating mjx before madrona\n",
    "        from mujoco import mjx\n",
    "        mjx_model = mjx.put_model(env_model)\n",
    "        mjx_data = mjx.make_data(mjx_model)\n",
    "        mjx_data = mjx_data.replace(qpos=jnp.array(init_qpos))\n",
    "        mjx_data = mjx.forward(mjx_model, mjx_data)\n",
    "\n",
    "        from quadruped_mjx_rl.environments.vision.robotic_vision import get_renderer\n",
    "        renderer_maker=functools.partial(get_renderer, vision_config=vision_config)\n",
    "        get_env_factory = functools.partial(\n",
    "            get_env_factory, vision_config=vision_config, renderer_maker=renderer_maker\n",
    "        )\n",
    "    env_factory = get_env_factory(\n",
    "        robot_config=robot_config,\n",
    "        environment_config=environment_config,\n",
    "        env_model=env_model,\n",
    "    )\n",
    "\n",
    "    logging.info(\"Initializing the environment...\")\n",
    "    env = env_factory()\n",
    "    if vision_config is None:\n",
    "        eval_env = env_factory()\n",
    "    else:\n",
    "        eval_env = None\n",
    "\n",
    "\n",
    "    trained_policy_save_path = trained_policy_dir / f\"{experiment_name}\"\n",
    "\n",
    "    print(f\"Starting training for: {experiment_name}\")\n",
    "    params = train(\n",
    "        training_env=env,\n",
    "        evaluation_env=eval_env,\n",
    "        model_config=model_config,\n",
    "        training_config=training_config,\n",
    "    )\n",
    "    from quadruped_mjx_rl.models.io import save_params\n",
    "    save_params(trained_policy_save_path, params)\n",
    "    print(f\"Trained policy saved to {trained_policy_save_path}\")\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Configure a rollout for rendering\n",
    "from quadruped_mjx_rl.config_utils import save_configs\n",
    "from quadruped_mjx_rl.policy_rendering import RenderConfig\n",
    "\n",
    "experiment_name = \"my_experiment\"  #@param {type:\"string\"}\n",
    "rollout_name = \"my_rollout\" # @param {type:\"string\"}\n",
    "\n",
    "n_steps = 500 # @param {\"type\":\"integer\"}\n",
    "render_every = 2 # @param {\"type\":\"integer\"}\n",
    "random_seed = 0 # @param {\"type\":\"integer\"}\n",
    "\n",
    "# @markdown ---\n",
    "# @markdown Joystick command for the robot to follow (in SI)\n",
    "x_vel = 0.8 # @param {\"type\":\"number\"}\n",
    "y_vel = 0.0 # @param {\"type\":\"number\"}\n",
    "ang_vel = 0.0 # @param {\"type\":\"number\"}\n",
    "\n",
    "render_config = RenderConfig(\n",
    "    n_steps=n_steps,\n",
    "    episode_length=n_steps * 2,\n",
    "    render_every=render_every,\n",
    "    seed=random_seed,\n",
    "    command={\n",
    "        \"x_vel\": x_vel,\n",
    "        \"y_vel\": y_vel,\n",
    "        \"ang_vel\": ang_vel,\n",
    "    },\n",
    ")\n",
    "\n",
    "config_file_path = rollout_configs_dir / f\"{experiment_name}_rendering_{rollout_name}.yaml\"\n",
    "save_configs(config_file_path, render_config)\n",
    "print(f\"Rollout configs saved to {config_file_path}\")\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Render all configured policy rollouts\n",
    "from quadruped_mjx_rl.policy_rendering import render_policy_rollout\n",
    "from quadruped_mjx_rl.environments import get_env_factory\n",
    "from quadruped_mjx_rl.config_utils import prepare_configs\n",
    "\n",
    "#@markdown All rollouts present will be rendered\n",
    "delete_rollouts_after_rendering = True # @param {\"type\":\"boolean\"}\n",
    "save_rollout_gifs = True # @param {\"type\":\"boolean\"}\n",
    "\n",
    "for experiment_config_file in configs_dir.iterdir():\n",
    "    if not experiment_config_file.name.endswith(\".yaml\"):\n",
    "        continue\n",
    "    experiment_name = experiment_config_file.stem\n",
    "    configs = prepare_configs(experiment_config_file)\n",
    "    environment_config = configs[\"environment\"]\n",
    "    robot_config = configs[\"robot\"]\n",
    "    model_config = configs[\"model\"]\n",
    "    vision_config = configs.get(\"vision\")\n",
    "\n",
    "    init_scene_path = repo_path / \"resources\" / robot_config.robot_name / \"scene_mjx.xml\"\n",
    "\n",
    "    env_factory, vision = get_env_factory(\n",
    "        env_config=environment_config,\n",
    "        robot_config=robot_config,\n",
    "        init_scene_path=init_scene_path,\n",
    "    )\n",
    "\n",
    "    trained_policy = trained_policy_dir / f\"{experiment_name}\"\n",
    "\n",
    "    rollout_configs_list = []\n",
    "    for rollout_config_file in rollout_configs_dir.iterdir():\n",
    "        if (\n",
    "            not rollout_config_file.name.endswith(\".yaml\")\n",
    "            or \"_rendering_\" not in rollout_config_file.name\n",
    "            or experiment_name != rollout_config_file.name.split(\"_rendering_\")[0]\n",
    "        ):\n",
    "            continue\n",
    "        rollout_configs_list.append(rollout_config_file)\n",
    "\n",
    "        render_config = prepare_configs(rollout_config_file)[\"render\"]\n",
    "\n",
    "        if save_rollout_gifs:\n",
    "            animation_save_path = animations_dir / f\"{rollout_config_file.stem}.gif\"\n",
    "        else:\n",
    "            animation_save_path = None\n",
    "\n",
    "        render_policy_rollout(\n",
    "            env_factory=env_factory,\n",
    "            model_config=model_config,\n",
    "            trained_model_path=trained_policy,\n",
    "            render_config=render_config,\n",
    "            animation_save_path=animation_save_path,\n",
    "            vision=vision,\n",
    "        )\n",
    "\n",
    "    if delete_rollouts_after_rendering:\n",
    "        for rollout_config_file in rollout_configs_list:\n",
    "            rollout_config_file.unlink()\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Saving results\n",
    "from google.colab import files, drive\n",
    "from etils.epath import Path\n",
    "\n",
    "#@markdown (This can be run in a separate session)\n",
    "\n",
    "#@markdown Choose what you want to save\n",
    "policies = True # @param {\"type\":\"boolean\"}\n",
    "rollout_gifs = True # @param {\"type\":\"boolean\"}\n",
    "config_files = True # @param {\"type\":\"boolean\"}\n",
    "#@markdown Only the configs for the training are saved\n",
    "\n",
    "#@markdown Choose whether you want to download your results\n",
    "download_results = False # @ param {\"type\":\"boolean\"}\n",
    "\n",
    "#@markdown Choose whether you want to save results to your Google drive\n",
    "save_to_drive = True # @param {\"type\":\"boolean\"}\n",
    "drive_save_folder = \"quadruped_mjx_rl_Results\" # @param {type:\"string\"}\n",
    "if save_to_drive:\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "for do_save, directory in zip(\n",
    "    [policies, rollout_gifs, config_files], [trained_policy_dir, animations_dir, configs_dir],\n",
    "):\n",
    "    if not do_save:\n",
    "        continue\n",
    "    for file_path in directory.iterdir():\n",
    "        if file_path.is_dir():\n",
    "            continue\n",
    "        if download_results:\n",
    "            files.download(file_path)\n",
    "        if save_to_drive:\n",
    "            drive_dir = Path(f\"/content/drive/MyDrive/{drive_save_folder}/{directory.name}\")\n",
    "            drive_dir.mkdir(parents=True, exist_ok=True)\n",
    "            file_path.copy(\n",
    "                dst=drive_dir / file_path.name, overwrite=True\n",
    "            )\n",
    "\n",
    "if save_to_drive:\n",
    "    drive.flush_and_unmount()"
   ],
   "id": "3707f41b1d929687"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
