{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexeiplatzer/unitree-go2-mjx-rl/blob/main/notebooks/colab_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "#@title Setup Runtime\n",
        "\n",
        "# Install the correct Jax version with CUDA enabled\n",
        "!pip install \"jax[cuda12]==0.5.1\"\n",
        "\n",
        "build_madrona_backend = False #@param {\"type\":\"boolean\"}\n",
        "\n",
        "if build_madrona_backend:\n",
        "    # Install additional missing packages\n",
        "    !sudo apt install -y libx11-dev libxrandr-dev libxinerama-dev libxcursor-dev libxi-dev mesa-common-dev\n",
        "\n",
        "    # Get Madrona MJX and its subpackages\n",
        "    !mkdir modules\n",
        "    !git clone https://github.com/shacklettbp/madrona_mjx.git modules/madrona_mjx\n",
        "    !git -C modules/madrona_mjx submodule update --init --recursive\n",
        "\n",
        "    # Build Madrona MJX\n",
        "    !mkdir modules/madrona_mjx/build\n",
        "    !cd modules/madrona_mjx/build && cmake -DLOAD_VULKAN=OFF .. && make -j 8\n",
        "\n",
        "    # Install Madrona MJX\n",
        "    !pip install -e modules/madrona_mjx\n",
        "\n",
        "# Clone and install our Quadruped RL package\n",
        "!git clone https://github.com/alexeiplatzer/unitree-go2-mjx-rl.git\n",
        "!pip install -e unitree-go2-mjx-rl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Refresh the package\n",
        "repo_path = \"./unitree-go2-mjx-rl\"\n",
        "!git -C {repo_path} pull"
      ],
      "metadata": {
        "id": "WmUiiCqMr2zB"
      },
      "id": "WmUiiCqMr2zB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup Session and Train\n",
        "\n",
        "# Configure logging\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, force=True)\n",
        "logging.info(\"Logging switched on.\")\n",
        "\n",
        "import os\n",
        "# Ensure that Madrona gets the chance to pre-allocate memory before Jax\n",
        "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
        "\n",
        "# On your second reading, load the compiled rendering backend to save time!\n",
        "use_madrona_cache = False #@param {\"type\":\"boolean\"}\n",
        "if use_madrona_cache:\n",
        "    os.environ[\"MADRONA_MWGPU_KERNEL_CACHE\"] = \"modules/madrona_mjx/build/cache\"\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "    with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "        f.write(\"\"\"{\n",
        "        \"file_format_version\" : \"1.0.0\",\n",
        "        \"ICD\" : {\n",
        "            \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "        }\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags\n",
        "\n",
        "# More legible printing from numpy.\n",
        "import numpy as np\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
        "\n",
        "# Prepare paths\n",
        "from etils.epath import Path\n",
        "repo_path = Path(\"unitree-go2-mjx-rl\")\n",
        "scenes_path = repo_path / \"resources\" / \"unitree_go2\"\n",
        "results_path = Path(\"results\")\n",
        "results_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Prepare configs\n",
        "from quadruped_mjx_rl.robots import predefined_robot_configs\n",
        "robot_config = predefined_robot_configs[\"unitree_go2\"]\n",
        "\n",
        "from quadruped_mjx_rl import environments\n",
        "env_config = environments.QuadrupedVisionTargetEnvConfig()\n",
        "\n",
        "from quadruped_mjx_rl import models\n",
        "model_architecture = \"ActorCritic\" #@param [\"ActorCritic\",\"TeacherStudent\",\"TeacherStudentVision\"]\n",
        "#@markdown ---\n",
        "#@markdown **Model hyperparameters for the Actor-Critic Architecture**\n",
        "if model_architecture == \"ActorCritic\":\n",
        "    policy_layers = [128, 128, 128, 128, 128] # @param\n",
        "    value_layers = [256, 256, 256, 256, 256] # @param\n",
        "\n",
        "    model_config_class = models.ActorCriticConfig\n",
        "    model_config = model_config_class(\n",
        "        modules=model_config_class.ModulesConfig(\n",
        "            policy=policy_layers,\n",
        "            value=value_layers,\n",
        "        ),\n",
        "    )\n",
        "#@markdown ---\n",
        "#@markdown **Model hyperparameters for the Teacher-Student Architecture**\n",
        "if model_architecture == \"TeacherStudent\":\n",
        "    policy_layers = [256, 256, 256] #@param\n",
        "    value_layers = [256, 256, 256] #@param\n",
        "    teacher_encoder_layers = [256, 256] #@param\n",
        "    student_encoder_layers = [256, 256] #@param\n",
        "    latent_representation_size = 64 # @param {\"type\":\"integer\"}\n",
        "\n",
        "    model_config_class = models.TeacherStudentConfig\n",
        "    model_config = model_config_class(\n",
        "        modules=model_config_class.ModulesConfig(\n",
        "            policy=policy_layers,\n",
        "            value=value_layers,\n",
        "            encoder=teacher_encoder_layers,\n",
        "            adapter=student_encoder_layers,\n",
        "        ),\n",
        "        latent_size=latent_representation_size,\n",
        "    )\n",
        "#@markdown ---\n",
        "#@markdown **Model hyperparameters for the Teacher-Student-Vision Architecture**\n",
        "if model_architecture == \"TeacherStudentVision\":\n",
        "    policy_layers = [128, 128] #@param\n",
        "    value_layers = [256, 256] #@param\n",
        "    teacher_encoder_convolutional_layers = [32, 64, 64] #@param\n",
        "    teacher_encoder_dense_layers = [256, 256] #@param\n",
        "    student_encoder_convolutional_layers = [32, 64, 64] #@param\n",
        "    student_encoder_dense_layers = [256, 256] #@param\n",
        "    latent_representation_size = 128 #@param {\"type\":\"integer\"}\n",
        "\n",
        "    model_config_class = models.TeacherStudentVisionConfig\n",
        "    model_config = model_config_class(\n",
        "        modules=model_config_class.ModulesConfig(\n",
        "            policy=policy_layers,\n",
        "            value=value_layers,\n",
        "            encoder_convolutional=teacher_encoder_convolutional_layers,\n",
        "            encoder_dense=teacher_encoder_dense_layers,\n",
        "            adapter_convolutional=student_encoder_convolutional_layers,\n",
        "            adapter_dense=student_encoder_dense_layers,\n",
        "        ),\n",
        "        latent_size=latent_representation_size,\n",
        "    )\n",
        "\n",
        "from quadruped_mjx_rl.training import configs as training_configs\n",
        "#@markdown ---\n",
        "#@markdown **PPO Hyperparameters**\n",
        "discounting = 0.97 #@param {\"type\":\"number\"}\n",
        "entropy_cost = 0.01 #@param {\"type\":\"number\"}\n",
        "clipping_epsilon = 0.3 #@param {\"type\":\"number\"}\n",
        "gae_lambda = 0.95 #@param {\"type\":\"number\"}\n",
        "normalize_advantage = True #@param {\"type\":\"boolean\"}\n",
        "reward_scaling = 1 #@param {\"type\":\"integer\"}\n",
        "learning_rate = 0.0004 #@param {\"type\":\"number\"}\n",
        "ppo_hyperparams = training_configs.HyperparamsPPO(\n",
        "    discounting=discounting,\n",
        "    entropy_cost=entropy_cost,\n",
        "    clipping_epsilon=clipping_epsilon,\n",
        "    gae_lambda=gae_lambda,\n",
        "    normalize_advantage=normalize_advantage,\n",
        ")\n",
        "#@markdown **Teacher-Student specific hyperparameters**\n",
        "#@markdown ---\n",
        "if model_architecture == \"TeacherStudent\" or model_architecture == \"TeacherStudentVision\":\n",
        "    student_learning_rate = 0.001 #@param {\"type\":\"number\"}\n",
        "    max_grad_norm = 1.0 #@param\n",
        "    optimizer_config = training_configs.TeacherStudentOptimizerConfig(\n",
        "        learning_rate=learning_rate,\n",
        "        student_learning_rate=student_learning_rate,\n",
        "        max_grad_norm=max_grad_norm,\n",
        "    )\n",
        "else:\n",
        "    optimizer_config = training_configs.OptimizerConfig(learning_rate=learning_rate)\n",
        "#@markdown ---\n",
        "#@markdown **Training hyperparameters without vision**\n",
        "if model_architecture == \"ActorCritic\" or model_architecture == \"TeacherStudent\":\n",
        "    num_envs = 8192 #@param {\"type\":\"integer\"}\n",
        "    num_eval_envs = 8192 #@param {\"type\":\"integer\"}\n",
        "    seed = 0 #@param {\"type\":\"integer\"}\n",
        "    num_timesteps = 100_000_000 #@param {\"type\":\"integer\"}\n",
        "    num_evals = 10 #@param {\"type\":\"integer\"}\n",
        "    deterministic_eval = False #@param {\"type\":\"boolean\"}\n",
        "    num_resets_per_eval = 0 #@param {\"type\":\"integer\"}\n",
        "    episode_length = 1000 #@param {\"type\":\"integer\"}\n",
        "    unroll_length = 20 #@param {\"type\":\"integer\"}\n",
        "    normalize_observations = True  #@param {\"type\":\"boolean\"}\n",
        "    action_repeat = 1 #@param {\"type\":\"integer\"}\n",
        "    batch_size = 256 #@param {\"type\":\"integer\"}\n",
        "    num_updates_per_batch = 4 #@param {\"type\":\"integer\"}\n",
        "    num_minibatches = 32 #@param {\"type\":\"integer\"}\n",
        "    training_config = training_configs.TrainingConfig(\n",
        "        num_envs=num_envs,\n",
        "        num_eval_envs=num_eval_envs,\n",
        "        seed=seed,\n",
        "        num_timesteps=num_timesteps,\n",
        "        num_evals=num_evals,\n",
        "        deterministic_eval=deterministic_eval,\n",
        "        num_resets_per_eval=num_resets_per_eval,\n",
        "        episode_length=episode_length,\n",
        "        unroll_length=unroll_length,\n",
        "        normalize_observations=normalize_observations,\n",
        "        action_repeat=action_repeat,\n",
        "        batch_size=batch_size,\n",
        "        num_updates_per_batch=num_updates_per_batch,\n",
        "        num_minibatches=num_minibatches,\n",
        "        rl_hyperparams=ppo_hyperparams,\n",
        "        optimizer=optimizer_config\n",
        "    )\n",
        "    vision_config = None\n",
        "#@markdown ---\n",
        "#@markdown **Training hyperparameters with vision**\n",
        "elif model_architecture == \"TeacherStudentVision\":\n",
        "    num_envs = 256 #@param {\"type\":\"integer\"}\n",
        "    num_eval_envs = 256 #@param {\"type\":\"integer\"}\n",
        "    seed = 0 #@param {\"type\":\"integer\"}\n",
        "    num_timesteps = 100_000_000 #@param {\"type\":\"integer\"}\n",
        "    num_evals = 10 #@param {\"type\":\"integer\"}\n",
        "    deterministic_eval = False #@param {\"type\":\"boolean\"}\n",
        "    num_resets_per_eval = 0 #@param {\"type\":\"integer\"}\n",
        "    episode_length = 1000 #@param {\"type\":\"integer\"}\n",
        "    unroll_length = 20 #@param {\"type\":\"integer\"}\n",
        "    normalize_observations = True  #@param {\"type\":\"boolean\"}\n",
        "    action_repeat = 1\n",
        "    batch_size = 256 #@param {\"type\":\"integer\"}\n",
        "    num_updates_per_batch = 4 #@param {\"type\":\"integer\"}\n",
        "    num_minibatches = 32 #@param {\"type\":\"integer\"}\n",
        "    training_config = training_configs.TrainingWithVisionConfig(\n",
        "        num_envs=num_envs,\n",
        "        num_eval_envs=num_eval_envs,\n",
        "        seed=seed,\n",
        "        num_timesteps=num_timesteps,\n",
        "        num_evals=num_evals,\n",
        "        deterministic_eval=deterministic_eval,\n",
        "        num_resets_per_eval=num_resets_per_eval,\n",
        "        episode_length=episode_length,\n",
        "        unroll_length=unroll_length,\n",
        "        normalize_observations=normalize_observations,\n",
        "        action_repeat=action_repeat,\n",
        "        batch_size=batch_size,\n",
        "        num_updates_per_batch=num_updates_per_batch,\n",
        "        num_minibatches=num_minibatches,\n",
        "        rl_hyperparams=ppo_hyperparams,\n",
        "        optimizer=optimizer_config,\n",
        "    )\n",
        "#@markdown **Vision renderer parameters**\n",
        "    from quadruped_mjx_rl.robotic_vision import VisionConfig\n",
        "    enabled_cameras=[1, 2] # @param\n",
        "    enabled_geom_groups=[0, 1, 2] # @param\n",
        "    render_width=64 #@param {\"type\":\"integer\"}\n",
        "    render_height=64 #@param {\"type\":\"integer\"}\n",
        "    vision_config = VisionConfig(\n",
        "        render_batch_size=training_config.num_envs,\n",
        "        enabled_cameras=enabled_cameras,\n",
        "        enabled_geom_groups=enabled_geom_groups,\n",
        "        render_width=render_width,\n",
        "        render_height=render_height,\n",
        "    )\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "# Set up the terrain\n",
        "init_scene_path = scenes_path / \"scene_mjx_cylinders.xml\"\n",
        "\n",
        "from quadruped_mjx_rl.terrain_gen import make_simple_obstacle_terrain, make_empty_terrain\n",
        "env_model = make_empty_terrain(init_scene_path)\n",
        "\n",
        "# Render the situation\n",
        "import mujoco\n",
        "from quadruped_mjx_rl.environments.rendering import render_model, show_image, large_overview_camera\n",
        "image = render_model(env_model, initial_keyframe=robot_config.initial_keyframe, camera=large_overview_camera())\n",
        "show_image(image)\n",
        "\n",
        "# Craft the env factory\n",
        "from quadruped_mjx_rl.environments import get_env_factory\n",
        "from quadruped_mjx_rl.robotic_vision import get_renderer\n",
        "import functools\n",
        "from jax import numpy as jnp\n",
        "\n",
        "renderer_maker = functools.partial(get_renderer, vision_config=vision_config, debug=True)\n",
        "env_factory = get_env_factory(\n",
        "    robot_config=robot_config,\n",
        "    environment_config=env_config,\n",
        "    env_model=env_model,\n",
        "    customize_model=True,\n",
        "    vision_config=vision_config,\n",
        "    renderer_maker=renderer_maker,\n",
        ")\n",
        "\n",
        "from mujoco import mjx\n",
        "mjx_model = mjx.put_model(env_model)\n",
        "mjx_data = mjx.make_data(mjx_model)\n",
        "# mjx_data = mjx_data.replace(qpos=jnp.array(init_qpos))\n",
        "mjx_data = mjx.forward(mjx_model, mjx_data)\n",
        "\n",
        "# Create the environment\n",
        "print(\"Setup finished, initializing the environment...\")\n",
        "env = env_factory()\n",
        "\n",
        "# Checkpointing\n",
        "# from quadruped_mjx_rl.training.checkpointing import policy_params_fn\n",
        "# params_save_path = results_path / \"params_checkpoints\"\n",
        "# params_save_path.mkdir(parents=True, exist_ok=True)\n",
        "# policy_params_fn = functools.partial(policy_params_fn, checkpoints_save_path=params_save_path)\n",
        "\n",
        "from quadruped_mjx_rl.models.io import save_params, load_params\n",
        "# restore_params = load_params(results_path / \"resulting_params\")\n",
        "logging.info(\"Params restored, starting training...\")\n",
        "\n",
        "# Try to launch a vision policy training\n",
        "from quadruped_mjx_rl.training.train_interface import train\n",
        "from quadruped_mjx_rl.domain_randomization.randomized_obstacles import terrain_randomize\n",
        "params = train(\n",
        "    training_config=training_config,\n",
        "    model_config=model_config,\n",
        "    training_env=env,\n",
        "    evaluation_env=None,\n",
        "    #randomization_fn=functools.partial(terrain_randomize, mj_model=env_model)\n",
        "    #restore_params=restore_params,\n",
        ")\n",
        "\n",
        "save_params(results_path / \"resulting_params\", params)"
      ],
      "metadata": {
        "id": "LaFfV3WIsAW-"
      },
      "id": "LaFfV3WIsAW-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}